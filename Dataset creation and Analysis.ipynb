{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d29227aa",
      "metadata": {
        "id": "d29227aa"
      },
      "source": [
        "# STAGE 0 - Python Setup\n",
        "\n",
        "- Run the code below to verify if the following packages are already installed, otherwise it will install them\n",
        "    - numpy, pandas, sklearn, scipy, networkx, matplotlib, tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "398c5c09",
      "metadata": {
        "id": "398c5c09",
        "outputId": "7ea20e00-bad6-4a69-8003-7e714773d22c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Il pacchetto 'numpy' è già installato.\n",
            "Il pacchetto 'pandas' è già installato.\n",
            "Il pacchetto 'sklearn' è già installato.\n",
            "Il pacchetto 'scipy' è già installato.\n",
            "Il pacchetto 'networkx' è già installato.\n",
            "Il pacchetto 'matplotlib' è già installato.\n",
            "Il pacchetto 'tqdm' è già installato.\n",
            "Il pacchetto 'xlsxwriter' è già installato.\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def verify_package(package_name):\n",
        "    try:\n",
        "        # Importa il pacchetto per verificare se è installato\n",
        "        __import__(package_name)\n",
        "        print(f\"Il pacchetto '{package_name}' è già installato.\")\n",
        "    except ImportError:\n",
        "        print(f\"Il pacchetto '{package_name}' non è installato. Installazione in corso...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name])\n",
        "\n",
        "list_packages = ['numpy','pandas', 'sklearn', 'scipy', 'networkx', 'matplotlib', 'tqdm', 'xlsxwriter']\n",
        "for package in list_packages:\n",
        "    verify_package(package)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b29c365",
      "metadata": {
        "id": "2b29c365"
      },
      "source": [
        "### Only for cleaning the texts\n",
        "- Run the code below to verify if the following packages are already installed, otherwise it will install them\n",
        "    - spacy, nltk, unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "588b3f16",
      "metadata": {
        "id": "588b3f16",
        "outputId": "7ebff75d-7270-4187-b574-da82e2992abf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Il pacchetto 'spacy' è già installato.\n",
            "Il pacchetto 'nltk' è già installato.\n",
            "Il pacchetto 'unidecode' è già installato.\n"
          ]
        }
      ],
      "source": [
        "list_packages_2 = ['spacy', 'nltk', 'unidecode']\n",
        "for package in list_packages_2:\n",
        "    verify_package(package)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c757279",
      "metadata": {
        "id": "5c757279"
      },
      "source": [
        "## Run the code below to import the functions for the analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "51aacb79",
      "metadata": {
        "id": "51aacb79"
      },
      "outputs": [],
      "source": [
        "import toolkit_functions as tlk"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e5a99c8",
      "metadata": {
        "id": "1e5a99c8"
      },
      "source": [
        "#\n",
        "#\n",
        "# STAGE 1 - Dataset creation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b03e38b8",
      "metadata": {
        "id": "b03e38b8"
      },
      "source": [
        "## Phase 1: Create the data frame from a file downloaded from Scopus or Web of Science"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5a52234",
      "metadata": {
        "id": "c5a52234"
      },
      "source": [
        "### Input from Web of Science\n",
        " - **filename**: name of the file downloaded from Web of Sciece with .txt extension. The file must be in the same folder of this Notebook.\n",
        "\n",
        "### Output\n",
        " - **Dataset_input.xslx** file: a data frame in which each row represents a paper and the columns are:\n",
        "     - text id; Authors; Article title; Abstract; Source title; Pubblication year; Journal abbreviation; Journal ISO abbreviation; References; Total number of citations; Number of internal citations; References internal id; DOI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67f36223",
      "metadata": {
        "id": "67f36223"
      },
      "outputs": [],
      "source": [
        "tlk.read_wos_txt(filename='your_file.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a5b4799",
      "metadata": {
        "id": "1a5b4799"
      },
      "source": [
        "## Or"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f971c5c",
      "metadata": {
        "id": "1f971c5c"
      },
      "source": [
        "### Input from Scopus\n",
        " - **filename**: name of the file downloaded from Scopus with .csv extension. The file must be in the same folder of this Notebook.\n",
        "\n",
        "### Output\n",
        " - **Dataset_input.xslx** file: a data frame in which each row represents a paper and the columns are:\n",
        "     - text id; Authors; Article title; Abstract; Source title; Pubblication year; Journal abbreviation; References; Total number of citations; Number of internal citations; References internal id; DOI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "dbb8ee19",
      "metadata": {
        "id": "dbb8ee19",
        "outputId": "212d261d-247a-460b-db74-6f63d1e8b120",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 empty abstracts\n",
            "The dataset has 656 documents\n",
            "removed 3 duplicated articles\n",
            "Counting the citations internal the dataset for each document...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "656it [00:38, 17.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving the file Dataset_input.xlsx\n"
          ]
        }
      ],
      "source": [
        "tlk.read_scopus_csv(filename='scopus_Q3.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d0e554c",
      "metadata": {
        "id": "4d0e554c"
      },
      "source": [
        "#\n",
        "# Phase 2: Add the top journal flags\n",
        "### Inputs:\n",
        " - **filename**: file to indicate which are the Top journals. The default file is 'TopJournal_list.txt' and the list was taken from https://journalranking.org considering all the journals ranked as 3, 4, and 4* according to the ABS ranking. If you want to use a different file, create a file .txt with the list of journals, where each journal name is divided by newline as in the file 'TopJournal_list.txt'.\n",
        "\n",
        "\n",
        " - **df_file**: name of the file with .xlsx extension. The file is a data frame created in the previuos step, named 'Dataset_input.xlsx'. The file is a data frame with a column, named 'source_title', that refers to the name of the journal where the paper was pubblished.\n",
        "\n",
        "### Output:\n",
        "- **Dataset_input.xslx** file: the input data frame  with a new column ('TOPJ') to indicate if the journal is top or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7cf00cc4",
      "metadata": {
        "id": "7cf00cc4"
      },
      "outputs": [],
      "source": [
        "tlk.add_top_journal(filename='TopJournal_list.txt', df_file='Dataset_input.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d98bcaeb",
      "metadata": {
        "id": "d98bcaeb"
      },
      "source": [
        "#\n",
        "# Phase 3: Clean the texts\n",
        "### Input:\n",
        "- **filename**: name of the file with .xlsx extension. The file is a data frame as created in the previuos step, named 'Dataset_input.xlsx'.\n",
        "    - Note: each text (abstract) should be a single string.\n",
        "\n",
        "### Output:\n",
        "- **Dataset_input.xslx** file: the input data frame with a new column ('clean_text) with the cleaned version of the abstract."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d152f08f",
      "metadata": {
        "id": "d152f08f",
        "outputId": "b540f141-ad55-47b0-e717-cb36d6a51ed1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaning the abstracts..\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Excel file format cannot be determined, you must specify an engine manually.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-4ee438cbfbe3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtlk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Dataset_input.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/toolkit_functions.py\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(filename, col)\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stopwords'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cleaning the abstracts..\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0mclean_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n\u001b[1;32m   1553\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1554\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m   1555\u001b[0m                         \u001b[0;34m\"Excel file format cannot be determined, you must specify \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m                         \u001b[0;34m\"an engine manually.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Excel file format cannot be determined, you must specify an engine manually."
          ]
        }
      ],
      "source": [
        "tlk.preprocess(filename='Dataset_input.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27df5633",
      "metadata": {
        "id": "27df5633"
      },
      "source": [
        "#\n",
        "# STAGE 2 - Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c87e0541",
      "metadata": {
        "id": "c87e0541"
      },
      "source": [
        "## Run the code below to import the functions for the analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "314519ad",
      "metadata": {
        "id": "314519ad"
      },
      "outputs": [],
      "source": [
        "import toolkit_functions as tlk"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a21be61d",
      "metadata": {
        "id": "a21be61d"
      },
      "source": [
        "#\n",
        "# Phase 3: Topic definition and document—topic associations\n",
        "##  Input values required to run the analysis:\n",
        "\n",
        "- **file_name**: name of the file created in Stage 1 (\"Dataset_Input.xlsx\").\n",
        "    - If you created your data frame skipping Stage 1, note that the input data frame must have the following columns:\n",
        "        - 'text_id': the identifier of the document, e.g. \"d1\".\n",
        "        - 'Total number of citations': total number of citations.\n",
        "        - 'clean_text': pre—processed text as string; words are separated by space.\n",
        "    \n",
        "\n",
        "\n",
        "- **method**: correction method for multiple testing problem: 'bonf' (Bonferroni correction) or 'fdr' (False Discovery Rate, (Benjamini Y and Hochberg Y, 1995)); the default value is 'fdr'.\n",
        "\n",
        "\n",
        "- **threshold**: value of the threshold to construct the Statistically Validated Network of words; the defaut value is 0.01.\n",
        "\n",
        "\n",
        "## Outputs:\n",
        "- **SVN words.txt** file: the edges list of the Statistically Validated Network of words; each row represents a link between two nodes ('source' and 'target') with its p-value and Pearson correlation coefficient. The file consists of four columns separated by '\\t':\n",
        "    - source, target, p-values, weight (Pearson correlation coefficient).\n",
        "    \n",
        "    \n",
        "- **Topic definition.xlsx** file: a data frame describing the Topics found as community of words in the Statistically Validated Network. The data frame has the following columns:\n",
        "    - 'topic': the identifier of the topic, e.g. \"topic_1\".\n",
        "    - 'word': the word in stemming form.\n",
        "    - 'modularity contribution': the importance of the node (word) within the community (topic) in terms of modularity contribution.\n",
        "    - 'original words': the list of words before the stemming procedure.\n",
        "\n",
        "\n",
        "- **Topic Document association.xlsx** file: a data frame describing the associations between documents and topics; \"topic_0\" represents the 'General' topic.  The data frame has the following columns:\n",
        "    - 'text_id': the identifier of the document, e.g. \"d1\".\n",
        "    - 'Article title': the title of the paper.\n",
        "    - 'topic': the identifier of the topic, e.g. \"topic_1\".\n",
        "    - 'p-value': the p-value of the over—expression of the topic within the document.\n",
        "    - 'correlation': Pearson correlation coefficient of the over—expression of the topic within the document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dac53b9",
      "metadata": {
        "id": "7dac53b9"
      },
      "outputs": [],
      "source": [
        "tlk.run_analysis(file_name='Dataset_input.xlsx', method='fdr', threshold=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir(os.getcwd())"
      ],
      "metadata": {
        "id": "L_ANUCd0zBBO",
        "outputId": "f95196c3-6bea-441d-eb7e-6b3bd7dd0e51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "L_ANUCd0zBBO",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'scopus_Q3.csv',\n",
              " '__pycache__',\n",
              " 'TopJournal_list.txt',\n",
              " 'Dataset_input.xlsx',\n",
              " '.ipynb_checkpoints',\n",
              " 'toolkit_functions.py',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "aa = pd.read_excel('Dataset_input.xlsx',  engine='xlrd')\n",
        "aa.head(2)"
      ],
      "metadata": {
        "id": "bxBVFYOrxQeZ",
        "outputId": "0f263fbd-8899-4973-824a-b165a12a57e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "id": "bxBVFYOrxQeZ",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "expected str, bytes or os.PathLike object, not NoneType",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-75049757af54>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Dataset_input.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'xlrd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0maa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1565\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1567\u001b[0;31m         self._reader = self._engines[engine](\n\u001b[0m\u001b[1;32m   1568\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1569\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Install xlrd >= 2.0.1 for xls Excel support\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xlrd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[0;34m(self, filepath_or_buffer, engine_kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows, ignore_workbook_corruption)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \"\"\"\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mfile_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;31m# We have to let unknown file formats pass through here, as some ancient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;31m# files that xlrd can parse don't start with the expected signature.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36minspect_format\u001b[0;34m(path, content)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mPEEK_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPEEK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/posixpath.py\u001b[0m in \u001b[0;36mexpanduser\u001b[0;34m(path)\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6299a04a",
      "metadata": {
        "id": "6299a04a"
      },
      "source": [
        "#\n",
        "# Phase 4: Statistics of the selected topics\n",
        "\n",
        "## Input values required:\n",
        "\n",
        "- **file_name1**: file with .xlsx extension. The file 'Dataset_Input.xlsx' was used as input in Phase 1.\n",
        "    - If you created your data frame skipping Stage 1, note that the input data frame must have the following columns:\n",
        "        - 'text_id': the identifier of the document, e.g. \"d1\".\n",
        "        - 'Total number of citations': total number of citations.\n",
        "        - 'Number of internal citations': number of citations within the dataset.\n",
        "        - 'TopJ': boolean (\"Y\" or \"N\") if the pubblication belongs to Top Journal or not.\n",
        "\n",
        "\n",
        "- **file_name2**:  file with .xlsx extension. The file 'Topic Document association.xlsx' was obtained in Phase 1.\n",
        "\n",
        "\n",
        "- **file_name3**: file with .xlsx extension. The file 'Topic definition.xlsx' was obtained in Phase 1.\n",
        "\n",
        "\n",
        "- **file_name4**: file with .xlsx extension. The file 'topic_label_example.xlsx' was created to store the labels of topics in STAGE 2 - Step 2. The file must be a data frame with two columns called 'topic' and 'label'. The column 'topic' contains the id of topics as in the file 'Topic definition.xlsx'. The column 'label' contains the name you assigned to the topic selected. The file 'topic_label_example.xlsx' is an example.\n",
        "\n",
        "## Outputs:\n",
        "\n",
        "- **stats_topic.xlsx** file: a data frame describing the topics and some related statistics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da44798c",
      "metadata": {
        "id": "da44798c"
      },
      "outputs": [],
      "source": [
        "tlk.run_stats(file_name1='Dataset_input.xlsx', file_name2='Topic Document association.xlsx',\n",
        "              file_name3='Topic definition.xlsx', file_name4='topic_label_example.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a82dbbc",
      "metadata": {
        "id": "8a82dbbc"
      },
      "source": [
        "#\n",
        "# Phase 5: Selection of articles\n",
        "\n",
        "## Input values required:\n",
        "\n",
        "- **file_name1**: file with .xlsx extension. The file 'Dataset_Input.xlsx' was used as input in Phase 1.\n",
        "    - If you created your data frame skipping Stage 1, note that the input data frame must have the following columns:\n",
        "        - 'text_id': the identifier of the document, e.g. \"d1\".\n",
        "        - 'Total number of citations': total number of citations.\n",
        "        - 'Number of internal citations': number of citations within the dataset.\n",
        "        - 'TopJ': boolean (\"Y\" or \"N\") if the pubblication belongs to Top Journal or not.\n",
        "\n",
        "\n",
        "- **file_name2**:  file with .xlsx extension. The file 'Topic Document association.xlsx' was obtained in Phase 1.\n",
        "\n",
        "\n",
        "- **file_name3**: file with .xlsx extension. The file 'topic_label_example.xlsx' was created to store the labels of topics in STAGE 2 - Step 2. The file must be a data frame with two columns called 'topic' and 'label'. The column 'topic' contains the id of topics as in the file 'Topic definition.xlsx'. The column 'label' contains the name you assigned to the topic selected. The file 'topic_label_example.xlsx' is an example.\n",
        "\n",
        "\n",
        "- **selection**: the selection criterion. You can use 'broad', selecting the papers with at least one citation in Scopus or Web of Science database,  or 'narrow', selecting the papers with at least one citation within the dataset downloaded. The default value is 'broad'.\n",
        "\n",
        "\n",
        "\n",
        "## Outputs:\n",
        "\n",
        "- **Final Dataset selection.xlsx** file: a data frame containing only the articles in the final selection that meet your filers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a53a1091",
      "metadata": {
        "id": "a53a1091"
      },
      "outputs": [],
      "source": [
        "tlk.dataset_selection(file_name1='Dataset_input.xlsx', file_name2='Topic Document association.xlsx',\n",
        "                      file_name3='topic_label_example.xlsx', selection='broad')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8127721a",
      "metadata": {
        "id": "8127721a"
      },
      "source": [
        "#\n",
        "#\n",
        "# STAGE 3 - Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8dcb596",
      "metadata": {
        "id": "a8dcb596"
      },
      "source": [
        "# Phase 6: Plot the selected topics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31b7143f",
      "metadata": {
        "id": "31b7143f"
      },
      "source": [
        "## Input:\n",
        "- **filename**: file with .xlsx extension. The output file 'stats_topic.xlsx' of Phase 4.\n",
        "- **name**: name of the file to save the plot.\n",
        "\n",
        "## Output:\n",
        "- Scatter-plot of topics along two dimensions: 'ratio of citations' (x-axis) and 'ratio of top journals' (y-axis). 'ratio of citations' is obtained as the 'Average number of citations within the dataset' divided by 'Average number of citations'. 'ratio of top journals' is obtained as the 'Number of papers from top journals over—expressed' divided by 'Number of papers over—expressed'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f30dba24",
      "metadata": {
        "id": "f30dba24"
      },
      "outputs": [],
      "source": [
        "tlk.plot_stats_1(filename='stats_topic.xlsx', name='topic_overview_1.pdf')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49851ddd",
      "metadata": {
        "id": "49851ddd"
      },
      "source": [
        "## Input:\n",
        "- **filename**: file with .xlsx extension. The output file 'stats_topic.xlsx' of Phase 4.\n",
        "- **name**: name of the file to save the plot.\n",
        "\n",
        "## Output:\n",
        "- Scatter-plot of topics along two dimensions: 'Average number of citations within the dataset' (x-axis) and 'Average number of citations' (y-axis)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47f61210",
      "metadata": {
        "id": "47f61210"
      },
      "outputs": [],
      "source": [
        "tlk.plot_stats_2(filename='stats_topic.xlsx', name='topic_overview_2.pdf')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}