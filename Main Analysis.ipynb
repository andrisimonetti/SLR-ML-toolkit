{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c786383",
   "metadata": {},
   "source": [
    "# 0. if you want to create your own DataFrame\n",
    "## The input DataFrame must have the following columns:\n",
    "\n",
    "- \"text_id\": id associated to each document\n",
    "    - example: [d1, d2, d3, ..., d100, ...]\n",
    "- \"tot_cit\": total number of citations\n",
    "- \"internal_cit\": number of citations within the dataset\n",
    "- \"references_internal_id\": string of text_id that cite the document separated by space\n",
    "    - example: \"d1 d2 d3 d4 d5 ..\"\n",
    "- \"TopJ\": boolean if the pubblication belongs to Top Journal or not\n",
    "- \"clean_text\": preprocessed text as string; words are separated by space\n",
    "\n",
    "### The file 'Dataset_input_example.xlsx' provides an example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a15738",
   "metadata": {},
   "source": [
    "# 1. Save the DataFrame in a file with name Dataset_Input.xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21be61d",
   "metadata": {},
   "source": [
    "# 2. Run the code below\n",
    "##  Input values required to run the analysis:\n",
    "\n",
    "- \"file_name\": name of the file created above (\"Dataset_Input.xlsx\") or in the Step-'Dataset_creation'; The file 'Dataset_Input_example.xlsx' is an example.\n",
    "\n",
    "\n",
    "- \"method_w\": correction method for multiple testing problem: 'bonf' (Bonferroni correction) or 'fdr' (False Discovery Rate, Benjamini Y and Hochberg Y, 1995); the default value is 'bonf'.\n",
    "\n",
    "\n",
    "- \"soglia_w\": value of the threshold to construct the Statistically Validated Network of words; the defaut value is 0.01.\n",
    "\n",
    "\n",
    "- \"soglia_d\": value of the threshold for document-topic associations with Bonferroni correction method, the defaut value is 0.01.\n",
    "\n",
    "\n",
    "- \"soglia_0\": value of the threshold to calculate the associations between documents and the 'General'-topic with the Bonferroni correction method; the defaut value is 0.01.\n",
    "\n",
    "\n",
    "## Outputs:\n",
    "- \"svn_words.txt\": file with the edges list of the Statistically Validated Network of words; each row represents a link between two nodes ('source' and 'target') with its p-value and Pearson correlation coefficient. The file consists of four columns separated by '\\t':\n",
    "    - source, target, p-values, weight (Pearson correlation coefficient)\n",
    "    \n",
    "    \n",
    "- 'topic_definition.xlsx': data frame describing the Topics found as community of words in the Statistically Validated Network.\n",
    "\n",
    "\n",
    "- 'Topic_Document_association.xlsx': data frame describing the associations between documents and topics; 'topic_0' represents the 'General' topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2c8a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import toolkit_functions as tlk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dac53b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tlk.run_analysis(file_name='Dataset_Input_example.xlsx', method_w='bonf', soglia_w=0.05,\n",
    "                 soglia_d=0.01, soglia_0=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da44798c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb2e186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
